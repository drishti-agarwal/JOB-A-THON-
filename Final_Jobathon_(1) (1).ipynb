{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Jobathon_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqHz14V_zVG7"
      },
      "source": [
        "# JOB-A-THON BY ANALYTICS VIDYA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIOmkn0bzidN"
      },
      "source": [
        "## APPROACH USED IN THE SOLUTION \n",
        "\n",
        "\n",
        "1.   **DATA CLEANING**\n",
        "> a) Rows with USERID as NULL were dropped.\n",
        "\n",
        "  >b) The activity, ProductID, OS features had values of string datatype in both uppercase and lowercase that was transformed with capitalise function.\n",
        "\n",
        "2.   **DATA TRANSFORMATION**\n",
        "> a) The VisitDateTime feature had values in both UNIX Timestamp format and Datetime format. This discrepancy was made uniform throughout the feature value.\n",
        "\n",
        "\n",
        "3.   **FEATURE WISE DATA ANALYSIS**\n",
        "> most_active_os- This was obtained by determining the mode value in the OS feature column for each group of USERIDs\n",
        "\n",
        "  > Recently_Viewed_Product- This was obtained by determining the particular record with max value in the VisitDateTime feature column for each group of USERIDs and the respective ProductID was stored.\n",
        "\n",
        "  > No_Of_Products_Viewed_15_Days- This was obtained by determining all the records that lie in the range of latest(max) VisitDateTime and 15 days before the latest(max) VisitDateTime for each group of USERIDs and then calculating the count of listed products of the selected records for each user.\n",
        "\n",
        "  > Most_Viewed_product_15_Days- This was obtained by determining all the records that have their VisitDateTime feature value greater than 2018-05-13 (this date was selected based on the values given for the datetime feature in the dataset). Now for each group of USERIDs, the most occurring productID was selected.\n",
        "\n",
        "  > Pageloads_last_7_days- This was obtained by determining all the records that lie in the range of latest(max) VisitDateTime and 7 days before the latest(max) VisitDateTime for each group of USERIDs and then calculating the count of records with Activity value as 'Pageload' for each group.\n",
        "\n",
        "  > Clicks_last_7_days- This was obtained by determining all the records that lie in the range of latest(max) VisitDateTime and 7 days before the latest(max) VisitDateTime for each group of USERIDs and then calculating the count of records with Activity value as 'Clicks' for each group.\n",
        "\n",
        "  > No_of_days_Visited_7_Days- This was obtained by determining all the records that have their VisitDateTime feature value greater than 2018-05-21 (this date was selected based on the values given for the datetime feature in the dataset). Now for each group of USERIDs, the unique occurrence of each date value was considered for the total count.\n",
        "\n",
        "  > User_Vintage- This was obtained by subtracting the signup date from 28-5-2018 (this date was selected based on the values given for the datetime feature in the dataset) for each USERID. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwogBw3OzeBK"
      },
      "source": [
        "# FUTURE SCOPE:\n",
        " 1. Use pyspark to create pipeline\n",
        " 2. Add testing to avoid corruption of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhmtM3h4nVU-"
      },
      "source": [
        "!unzip -q /content/drive/MyDrive/Copy\\ of\\ data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB7WLjYkyd9E",
        "outputId": "31c41530-ce77-4d46-ed7a-018bdee0f9b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j-bvSfK5UXC"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZGhJg0R_u9e"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cRe7R4-Gfcx"
      },
      "source": [
        "from datetime import timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bofMTBfv_eY"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwzcCE-92U5k"
      },
      "source": [
        "def load_data(visfile,usrfile,dat):\n",
        "  vis = pd.read_csv(visfile)\n",
        "  usr = pd.read_csv(usrfile)\n",
        "  return vis,usr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjTRRyci5NS-"
      },
      "source": [
        "vis,usr = load_data('/content/data/VisitorLogsData.csv','/content/data/userTable.csv',12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_inl78_43fq3"
      },
      "source": [
        "class Pipeline:\n",
        "  def __init__(self,visdf,usrdf,day,month,year):\n",
        "    self.vis = visdf\n",
        "    self.usr = usrdf\n",
        "    self.day = int(day)\n",
        "    self.month = int(month)\n",
        "    self.year = int(year)\n",
        "    self.sub = pd.DataFrame()\n",
        "\n",
        "  def clean_data(self):\n",
        "    print('Cleaning Data.....')\n",
        "    self.vis.dropna(subset = ['UserID'],inplace = True)\n",
        "    self.vis['Activity'] = self.vis['Activity'].apply(lambda x: x.capitalize() if not pd.isnull(x) else x)\n",
        "    self.vis['OS'] = self.vis['OS'].apply(lambda x: x.capitalize() if not pd.isnull(x) else x)\n",
        "    self.vis['ProductID'] = self.vis['ProductID'].apply(lambda x: x.capitalize() if not pd.isnull(x) else x)\n",
        "    self.vis = pd.merge(self.vis,self.usr,how = 'left',on='UserID')\n",
        "    self.vis['Activity'] = self.vis['Activity'].bfill()\n",
        "    self.vis.sort_values(by = 'UserID',inplace = True)\n",
        "    self.sub['UserID'] = self.vis['UserID'].unique()\n",
        "\n",
        "  def check_date(self):\n",
        "    print('Cleaning Date.....')\n",
        "    self.df2 = self.vis[~self.vis['VisitDateTime'].isnull()]\n",
        "    self.df2['VisitDateTime'] = self.df2['VisitDateTime'].apply(lambda x: pd.to_datetime(int(x)//10**9,unit = 's',errors = 'ignore') if '-' not in x else pd.to_datetime(x,format = '%Y-%m-%d %H:%M:%S'))\n",
        "    for x in self.df2.index:\n",
        "      self.vis.loc[x,'VisitDateTime'] = self.df2.loc[x,'VisitDateTime']\n",
        "    self.vis['VisitDateTime']=pd.to_datetime(self.vis['VisitDateTime'], format='%Y%m%d%H%M%S%f')\n",
        "  def mergedf(self,df):\n",
        "    self.sub = pd.merge(self.sub,df,how = 'left',on='UserID')\n",
        "\n",
        "\n",
        "  def most_active_os(self):\n",
        "    print('Fetching Most Active OS.....')\n",
        "    self.sub['Most_Active_OS'] = self.vis.groupby('UserID')['OS'].agg(pd.Series.mode).values\n",
        "\n",
        "  def most_rec_viewed(self):\n",
        "    print('Fetching Most Recent Viewed Products.....')\n",
        "    self.df4 = self.vis[~self.vis['VisitDateTime'].isna()]\n",
        "    self.df4 = self.df4[~self.df4['ProductID'].isna()]\n",
        "    self.most_rec_view = self.df4[self.df4.groupby('UserID')['VisitDateTime'].transform(max)==self.df4['VisitDateTime']]\n",
        "    self.most_rec_view.drop_duplicates(['ProductID','UserID'],inplace = True)\n",
        "    self.most_rec_view = self.most_rec_view[['UserID','ProductID']]\n",
        "    self.most_rec_view.rename(columns = {'ProductID':'Recently_Viewed_Product'},inplace = True)\n",
        "    self.mergedf(self.most_rec_view)\n",
        "    self.sub['Recently_Viewed_Product'].fillna('Product101',inplace = True)\n",
        "\n",
        "\n",
        "  def product_views(self):\n",
        "    print('Fetching Product Views.....')\n",
        "    self.df3 = self.vis[~self.vis['ProductID'].isna()]\n",
        "    self.df3 = self.df3[~self.df3['VisitDateTime'].isna()]\n",
        "    self.df3 = self.df3[self.df3['VisitDateTime']>=self.df3['VisitDateTime'].max()-timedelta(days=15)]\n",
        "    self.num_prod_views = self.df3.groupby('UserID')['ProductID'].nunique()\n",
        "    self.num_prod_views = pd.DataFrame(self.num_prod_views)\n",
        "    self.num_prod_views.rename(columns={'ProductID':'No_Of_Products_Viewed_15_Days'},inplace = True)\n",
        "    self.num_prod_views.reset_index(inplace = True)\n",
        "    self.mergedf(self.num_prod_views)\n",
        "    self.sub['No_Of_Products_Viewed_15_Days'].fillna(0,inplace = True)\n",
        "\n",
        "  def most_viewed(self):\n",
        "    print('Fetching Most Viewed Product.....')\n",
        "    self.df6 = self.vis[~self.vis['VisitDateTime'].isna()]\n",
        "    self.last_15_days = self.df6[self.df6['VisitDateTime'] >= '2018-05-13']\n",
        "    self.last_15_days = self.last_15_days[~self.last_15_days['ProductID'].isna()]\n",
        "    self.last_15_days = self.last_15_days.groupby('UserID')['ProductID'].apply(lambda x: x.value_counts().index[0])\n",
        "    self.last_15_days = pd.DataFrame(self.last_15_days)\n",
        "    self.last_15_days.reset_index(inplace = True)\n",
        "    self.last_15_days.rename(columns = {'ProductID':'Most_Viewed_product_15_Days'},inplace = True)\n",
        "    self.mergedf(self.last_15_days)\n",
        "    self.sub['Most_Viewed_product_15_Days'].fillna('Product101',inplace = True)\n",
        "\n",
        "  def pageloads_and_clicks(self):\n",
        "    print('Fetching Pageloads and Clicks.....')\n",
        "    self.df5 = self.vis[~self.vis['VisitDateTime'].isna()]\n",
        "    self.df5.dropna(subset = ['Activity'],inplace = True)\n",
        "    self.df5 = self.df5[self.df5['VisitDateTime']>= self.df5['VisitDateTime'].max()-timedelta(days=7)]\n",
        "    self.pageloads = pd.DataFrame(self.df5[self.df5['Activity']=='Pageload'].groupby('UserID')['Activity'].count())\n",
        "    self.pageloads.rename(columns = {'Activity':'Pageloads_last_7_days'},inplace = True)\n",
        "    self.clicks = pd.DataFrame(self.df5[self.df5['Activity']=='Click'].groupby('UserID')['Activity'].count())\n",
        "    self.clicks.rename(columns = {'Activity':'Clicks_last_7_days'},inplace = True)\n",
        "    self.pageloads.reset_index(inplace = True)\n",
        "    self.clicks.reset_index(inplace = True)\n",
        "    self.mergedf(self.pageloads)\n",
        "    self.mergedf(self.clicks)\n",
        "    self.sub['Pageloads_last_7_days'].fillna(0,inplace = True)\n",
        "    self.sub['Clicks_last_7_days'].fillna(0,inplace = True)\n",
        "\n",
        "  def no_of_days_visited(self):\n",
        "    print('Fetching No. of Days Visited.....')\n",
        "    self.feature = self.vis[self.vis['VisitDateTime'] >= '2018-05-21']\n",
        "    self.feature = self.feature[~self.feature['Activity'].isna()]\n",
        "    self.feature[\"Date\"] = self.feature['VisitDateTime'].dt.date\n",
        "    self.No_of_day_Visited_7_days = self.feature.groupby('UserID')['Date'].nunique().reset_index(name='No_of_days_Visited_7_Days')\n",
        "    self.mergedf(self.No_of_day_Visited_7_days)\n",
        "    self.sub['No_of_days_Visited_7_Days'].fillna(0,inplace = True)\n",
        "\n",
        "  def user_vintage(self):\n",
        "    print('Fetching User Vintage.....')\n",
        "    self.vis['Signup Date'] = pd.to_datetime(self.vis['Signup Date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
        "    self.df8 = self.vis[['Signup Date','UserID']]\n",
        "    self.df8['Signup Date Filtered'] = self.df8['Signup Date'].dt.date\n",
        "    self.df8['User_Vintage'] = datetime.date(year = self.year,month = self.month,day = self.day)-self.df8['Signup Date Filtered']\n",
        "    self.df8['User_Vintage'] = self.df8['User_Vintage'].dt.days.astype(int)\n",
        "    self.uv = self.df8.groupby('UserID')['User_Vintage'].mean()\n",
        "    self.uv = pd.DataFrame(self.uv,columns = ['User_Vintage']).reset_index()\n",
        "    self.mergedf(self.uv)\n",
        "\n",
        "  def create_submission(self):\n",
        "    self.clean_data()\n",
        "    self.check_date()\n",
        "    self.most_rec_viewed()\n",
        "    self.most_active_os()\n",
        "    self.product_views()\n",
        "    self.pageloads_and_clicks()\n",
        "    self.most_viewed()\n",
        "    self.no_of_days_visited()\n",
        "    self.user_vintage()\n",
        "    self.sub['No_of_days_Visited_7_Days'] = self.sub['No_of_days_Visited_7_Days'].astype(int)\n",
        "    self.sub['Pageloads_last_7_days'] = self.sub['Pageloads_last_7_days'].astype(int)\n",
        "    self.sub['Clicks_last_7_days'] = self.sub['Clicks_last_7_days'].astype(int) \n",
        "    self.sub = self.sub[['UserID','No_of_days_Visited_7_Days','No_Of_Products_Viewed_15_Days','User_Vintage','Most_Viewed_product_15_Days','Most_Active_OS','Recently_Viewed_Product','Pageloads_last_7_days','Clicks_last_7_days']]\n",
        "    self.sub.to_csv('Submission.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shASGnuF6nHi"
      },
      "source": [
        "obj = Pipeline(vis,usr,28,5,2018)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyvJSNGR3fzX",
        "outputId": "5f01aeda-e71a-41d9-9a8b-b43253f1050c"
      },
      "source": [
        "obj.create_submission()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning Data.....\n",
            "Cleaning Date.....\n",
            "Fetching Most Recent Viewed Products.....\n",
            "Fetching Most Active OS.....\n",
            "Fetching Product Views.....\n",
            "Fetching Pageloads and Clicks.....\n",
            "Fetching Most Viewed Product.....\n",
            "Fetching No. of Days Visited.....\n",
            "Fetching User Vintage.....\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}